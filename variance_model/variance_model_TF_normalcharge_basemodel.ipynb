{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.7/bin\") # path to nvidia dlls, must have CUDA drivers installed\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import mixed_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Acceleration\n",
    "\n",
    "** IMPORTANT NOTE **\n",
    " - You must have CUDA driver and CUDA toolkit installed on your machine. To do so, follow the instructions here:\n",
    "https://www.tensorflow.org/install/pip\n",
    "\n",
    "- Enable GPU Acceleration if you have a NVIDIA GPU with compute capability >= 7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "\n",
    "# ## ENABLE THIS IF YOU HAVE RTX GPU WITH COMPUTE CAPABILITY 7.0 or higher\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_global_policy(policy)\n",
    "# print('Compute dtype: %s' % policy.compute_dtype)\n",
    "# print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"../data/features_combined.csv\"\n",
    "batch_pd = pd.read_csv(fp, index_col=False)\n",
    "dataset = batch_pd.copy()\n",
    "dataset.sort_values(by=['policy'], ascending=True, inplace=True)\n",
    "\n",
    "# dataset\n",
    "dataset.isna().sum()\n",
    "dataset = dataset.dropna().drop(columns=['policy', 'barcode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run setup\n",
    "1. Adjust global model config to test the model settings\n",
    "2. Change the Run configuration to define the saved location for the results and the number of runs\n",
    "3. Run the notebook\n",
    "4. Clear output and restart the notebook for the next run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global Model Config\n",
    "EPOCHS = 2500 # number of epochs to train the model\n",
    "UNITS = 1 # number of units/nodes in the hidden layer\n",
    "LEARNING_RATE = 0.01 # learning rate for the model\n",
    "CALLBACK = tf.keras.callbacks.EarlyStopping(monitor='RMSE', patience=15, min_delta=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the run setup\n",
    "\n",
    "RUN_NUMBER = 1 # Test run number\n",
    "SAVED_RESULT_PATH = \"../variance_model/results/test_run#\" + str(RUN_NUMBER) # path to saved results\n",
    "\n",
    "if ( os.path.exists(SAVED_RESULT_PATH) ):\n",
    "    print(\"Directory \" , SAVED_RESULT_PATH , \" already exists\")\n",
    "else:\n",
    "    os.mkdir(SAVED_RESULT_PATH)\n",
    "    print(\"Directory \" , SAVED_RESULT_PATH , \" created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split\n",
    "Split by policy fast charge first(5C - 8C), and then by policy slow charge (1C - 4C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_charge_dataset = dataset.iloc[0:29, :] # 29 data points\n",
    "print(normal_charge_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal-Charge Test-Train split\n",
    "Selecting alternate batteries for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_charge_train_ds = normal_charge_dataset.iloc[0::2, :]\n",
    "normal_charge_test_ds = normal_charge_dataset.iloc[1::2, :]\n",
    "\n",
    "normalcharge_train_features = normal_charge_train_ds.copy()\n",
    "normalcharge_test_features = normal_charge_test_ds.copy()\n",
    "\n",
    "normal_train_labels = normalcharge_train_features.pop('cycle_life')\n",
    "normal_test_labels = normalcharge_test_features.pop('cycle_life')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regress\n",
    "### Layering and Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize layer\n",
    "QDiffLinVar = np.array(normalcharge_train_features['QDiffLinVar'])\n",
    "QDiffLinVar_normalizer = layers.Normalization(input_shape=[1,], axis=None)\n",
    "QDiffLinVar_normalizer.adapt(QDiffLinVar)\n",
    "\n",
    "variance_normalcharge_basemodel = tf.keras.Sequential([\n",
    "    QDiffLinVar_normalizer,\n",
    "    layers.Dense(UNITS, input_dim=1, activation='relu'),\n",
    "    layers.Dense(1, activation='linear', dtype='float32', name='predictions')\n",
    "])\n",
    "variance_normalcharge_basemodel.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[ \n",
    "        tf.keras.metrics.RootMeanSquaredError( name='RMSE'), \n",
    "        'mae']\n",
    "    )\n",
    "\n",
    "variance_normalcharge_basemodel.summary()\n",
    "\n",
    "print(\"Number of weights weights:\", len(variance_normalcharge_basemodel.weights))\n",
    "print(\"trainable_weights:\", len(variance_normalcharge_basemodel.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(variance_normalcharge_basemodel.non_trainable_weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = variance_normalcharge_basemodel.fit(\n",
    "    normalcharge_train_features['QDiffLinVar'],\n",
    "    normal_train_labels,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    callbacks=[CALLBACK],\n",
    "    validation_data=(normalcharge_test_features['QDiffLinVar'], normal_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss graph and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(basemodel_hist):\n",
    "  plt.figure(\"Normal-charge base model loss\", figsize=(5,5), dpi=100, facecolor='w', edgecolor='k')\n",
    "  plt.plot(basemodel_hist['RMSE'], label='loss_base', color='red')\n",
    "  plt.plot(basemodel_hist['val_RMSE'], label='val_loss_base', color='green', linestyle='dashed')\n",
    "  plt.ylim([0, 800])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [cycles]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.title('Normal-charge base model loss')\n",
    "  plt.savefig(SAVED_RESULT_PATH + \"/normalcharge_basemodel_loss_RUN#\" + str(RUN_NUMBER) + \".png\")\n",
    "\n",
    "## Display model's loss and accuracy history\n",
    "basemodel_history = pd.DataFrame(history.history)\n",
    "basemodel_history.to_csv(SAVED_RESULT_PATH + \"/normalcharge_basemodel_history_RUN#\" + str(RUN_NUMBER) + \".csv\")\n",
    "basemodel_history\n",
    "\n",
    "plot_loss(basemodel_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "test_results['variance_normalcharge_basemodel'] = variance_normalcharge_basemodel.evaluate(\n",
    "    normalcharge_test_features['QDiffLinVar'],\n",
    "    normal_test_labels, verbose=1) #sqrt for mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(y_train, y_test):\n",
    "  plt.figure(\"Normal-charge base model loss\", figsize=(5,5), dpi=100, facecolor='w', edgecolor='k')\n",
    "  plt.axes(aspect='equal')\n",
    "  plt.scatter(y_train, normal_train_labels, label='Predictions (train)')\n",
    "  plt.scatter(y_test, normal_test_labels, label='Predictions (test)', marker='^')\n",
    "  lims = [0, 2000]\n",
    "  plt.xlim(lims)\n",
    "  plt.ylim(lims)\n",
    "  plt.plot(lims, lims, 'k', )\n",
    "  plt.xlabel('Predicted Cycle life')\n",
    "  plt.ylabel('Actual Cycle life')\n",
    "  plt.legend()\n",
    "  plt.title('Normal-charge Model Prediction')\n",
    "  plt.savefig( SAVED_RESULT_PATH + '/normalcharge_basemodel_prediction_RUN#' + str(RUN_NUMBER) + \".png\")\n",
    "\n",
    "normal_train_prediction = variance_normalcharge_basemodel.predict(normal_charge_train_ds['QDiffLinVar'])\n",
    "normal_test_prediction = variance_normalcharge_basemodel.predict(normal_charge_test_ds['QDiffLinVar'])\n",
    "plot_prediction(normal_train_prediction, normal_test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(test_results, index=['MSE', 'RMSE', 'MAE']).T\n",
    "result.to_csv( SAVED_RESULT_PATH + '/normalcharge_basemodel_result_RUN#' + str(RUN_NUMBER) + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_normalcharge_basemodel.save('../variance_model/saved_model/variance_normalcharge_basemodel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa8930a7197b489e49b22ce0be0acfdea3c455a79a3fdaa498eaf8f0b77d2696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

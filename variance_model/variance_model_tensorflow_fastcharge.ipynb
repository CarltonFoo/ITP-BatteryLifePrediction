{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q numpy pandas matplotlib seaborn scikit-learn tensorflow h5py tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.7/bin\") // path to nvidia dlls, must have CUDA drivers installed\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import mixed_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Acceleration\n",
    "\n",
    "** IMPORTANT NOTE **\n",
    " - You must have CUDA driver and CUDA toolkit installed on your machine. To do so, follow the instructions here:\n",
    "https://www.tensorflow.org/install/pip\n",
    "\n",
    "- Enable GPU Acceleration if you have a NVIDIA GPU with compute capability >= 7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "\n",
    "# ## ENABLE THIS IF YOU HAVE RTX GPU WITH COMPUTE CAPABILITY 7.0 or higher\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_global_policy(policy)\n",
    "# print('Compute dtype: %s' % policy.compute_dtype)\n",
    "# print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"./features_combined.csv\"\n",
    "batch_pd = pd.read_csv(fp, index_col=False)\n",
    "dataset = batch_pd.copy()\n",
    "dataset.sort_values(by=['policy'], ascending=True, inplace=True)\n",
    "\n",
    "# dataset\n",
    "dataset.isna().sum()\n",
    "dataset = dataset.dropna().drop(columns=['policy', 'barcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global Model Config\n",
    "EPOCHS = 2500\n",
    "UNITS = 1\n",
    "LEARNING_RATE = 0.01\n",
    "CALLBACK = tf.keras.callbacks.EarlyStopping(monitor='mae', patience=15, min_delta=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split\n",
    "Split by policy fast charge first(5C - 8C), and then by policy slow charge (1C - 4C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_charge_dataset = dataset.iloc[0:29, :] # 29 data points\n",
    "fast_charge_dataset = dataset.iloc[29:, :] # 51 data points \n",
    "print(normal_charge_dataset.shape, fast_charge_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast-Charge Test-Train split\n",
    "Selecting alternate batteries for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_charge_train_ds = fast_charge_dataset.iloc[0::2, :]\n",
    "fast_charge_test_ds = fast_charge_dataset.iloc[1::2, :]\n",
    "fast_charge_train_ds.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcharge_train_features = fast_charge_train_ds.copy()\n",
    "fastcharge_test_features = fast_charge_test_ds.copy()\n",
    "\n",
    "train_labels = fastcharge_train_features.pop('cycle_life')\n",
    "test_labels = fastcharge_test_features.pop('cycle_life')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regress\n",
    "### Layering and Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize layer\n",
    "QDiffLinVar = np.array(fastcharge_train_features['QDiffLinVar'])\n",
    "QDiffLinVar_normalizer = layers.Normalization(input_shape=[1,], axis=None)\n",
    "QDiffLinVar_normalizer.adapt(QDiffLinVar)\n",
    "\n",
    "# Input and output layers\n",
    "variance_model_fast_charge = tf.keras.Sequential([\n",
    "    QDiffLinVar_normalizer,\n",
    "    layers.Dense(UNITS, input_dim=1 ,activation='relu' ),\n",
    "    layers.Dense(1, activation='linear', dtype='float32', name='predictions')\n",
    "])\n",
    "variance_model_fast_charge.summary()\n",
    "\n",
    "print(\"Number of weights after calling the model:\", len(variance_model_fast_charge.weights))\n",
    "print(\"weights:\", len(variance_model_fast_charge.weights))\n",
    "print(\"trainable_weights:\", len(variance_model_fast_charge.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(variance_model_fast_charge.non_trainable_weights))\n",
    "\n",
    "## Compile the model and make a prediction\n",
    "variance_model_fast_charge.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=['mae']\n",
    "    )\n",
    "\n",
    "## Making a prediction on first 10 samples\n",
    "variance_model_fast_charge.predict(QDiffLinVar[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "history = variance_model_fast_charge.fit(\n",
    "    fastcharge_train_features['QDiffLinVar'],\n",
    "    train_labels,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    # callbacks=[CALLBACK],\n",
    "    validation_data=(fastcharge_test_features['QDiffLinVar'], test_labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.figure(\"BaseMode\", figsize=(5,5), dpi=100, facecolor='w', edgecolor='k')\n",
    "  plt.plot(np.sqrt(history.history['loss']), label='loss')\n",
    "  plt.plot(np.sqrt(history.history['val_loss']), label='val_loss')\n",
    "  # plt.ylim([200, 130])\n",
    "  plt.ylim([10, 800])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [cycles]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  \n",
    "plot_loss(history)\n",
    "\n",
    "## Display model's loss and accuracy history\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist = hist.pow(0.5) # Power 1/2 is the same as square root\n",
    "hist['epoch'] = history.epoch\n",
    "hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model and Save the Results for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "test_results['fast_charge_variance_model'] = variance_model_fast_charge.evaluate(\n",
    "    fastcharge_test_features['QDiffLinVar'],\n",
    "    test_labels, verbose=1) #sqrt for mse\n",
    "## Based on Author's calculation for MSE\n",
    "test_results['fast_charge_variance_model'][0] = test_results['fast_charge_variance_model'][0] ** 0.5\n",
    "pd.DataFrame(test_results, index=['MSE', 'MAE']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(y_train, y_test):\n",
    "  plt.figure(\"BaseModelPrediction\", figsize=(5,5), dpi=100, facecolor='w', edgecolor='k')\n",
    "  plt.axes(aspect='equal')\n",
    "  plt.scatter(y_train, train_labels, label='Predictions (train)')\n",
    "  plt.scatter(y_test, test_labels, label='Predictions (test)')\n",
    "  lims = [0, 2000]\n",
    "  plt.xlim(lims)\n",
    "  plt.ylim(lims)\n",
    "  plt.plot(lims, lims, 'k', )\n",
    "  plt.xlabel('Predicted Cycle life')\n",
    "  plt.ylabel('Actual Cycle life')\n",
    "  plt.legend()\n",
    "\n",
    "train_prediction = variance_model_fast_charge.predict(fast_charge_train_ds['QDiffLinVar'])\n",
    "test_prediction = variance_model_fast_charge.predict(fast_charge_test_ds['QDiffLinVar'])\n",
    "train_prediction\n",
    "plot_prediction(train_prediction, test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal-charge Data Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_charge_train_ds = normal_charge_dataset.iloc[0::2, :]\n",
    "normal_charge_test_ds = normal_charge_dataset.iloc[1::2, :]\n",
    "\n",
    "normalcharge_train_features = normal_charge_train_ds.copy()\n",
    "normalcharge_test_features = normal_charge_test_ds.copy()\n",
    "\n",
    "normal_train_labels = normalcharge_train_features.pop('cycle_life')\n",
    "normal_test_labels = normalcharge_test_features.pop('cycle_life')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a copy of base model\n",
    "variance_model_normal_charge_tl = variance_model_fast_charge\n",
    "## Freezing every layer except the last layer\n",
    "for layer in variance_model_normal_charge_tl.layers[:-1]:\n",
    "  layer.trainable = False\n",
    "variance_model_normal_charge_tl.summary()\n",
    "\n",
    "variance_model_normal_charge_tl.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=['mae']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_model_normal_charge_traditional = tf.keras.Sequential([\n",
    "    QDiffLinVar_normalizer,\n",
    "    layers.Dense(UNITS, input_dim=1, activation='relu'),\n",
    "    layers.Dense(1, activation='linear', dtype='float32', name='predictions')\n",
    "])\n",
    "variance_model_normal_charge_traditional.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=['mae']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_tl = variance_model_normal_charge_tl.fit(\n",
    "    normalcharge_train_features['QDiffLinVar'],\n",
    "    normal_train_labels,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    validation_data=(normalcharge_test_features['QDiffLinVar'], normal_test_labels),\n",
    "    callbacks=[CALLBACK]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_traditional = variance_model_normal_charge_traditional.fit(\n",
    "    normalcharge_train_features['QDiffLinVar'],\n",
    "    normal_train_labels,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    # callbacks=[CALLBACK],\n",
    "    validation_data=(normalcharge_test_features['QDiffLinVar'], normal_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss graph and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(hist_trad, hist_tl):\n",
    "  plt.figure(\"TransferLearning vs Traditional\", figsize=(5,5), dpi=100, facecolor='w', edgecolor='k')\n",
    "  plt.plot(np.sqrt(hist_trad.history['loss']), label='loss_traditional')\n",
    "  plt.plot(np.sqrt(hist_trad.history['val_loss']), label='val_loss_traditional')\n",
    "  plt.plot(np.sqrt(hist_tl.history['loss']), label='loss_tl')\n",
    "  plt.plot(np.sqrt(hist_tl.history['val_loss']), label='val_loss_tl')\n",
    "  # plt.ylim([200, 130])\n",
    "  plt.ylim([10, 800])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [cycles]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "plot_loss(history_traditional, history_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['normal_charge_variance_model_tl'] = variance_model_normal_charge_tl.evaluate(\n",
    "    normalcharge_test_features['QDiffLinVar'],\n",
    "    normal_test_labels, verbose=1) #sqrt for mse\n",
    "test_results['normal_charge_variance_model_traditional'] = variance_model_normal_charge_traditional.evaluate(\n",
    "    normalcharge_test_features['QDiffLinVar'],\n",
    "    normal_test_labels, verbose=1) #sqrt for mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(y_train, y_test):\n",
    "  plt.figure(\"Transfer Learning vs Traditional\", figsize=(5,5), dpi=100, facecolor='w', edgecolor='k')\n",
    "  plt.axes(aspect='equal')\n",
    "  plt.scatter(y_train, normal_train_labels, label='Predictions (train)')\n",
    "  plt.scatter(y_test, normal_test_labels, label='Predictions (test)')\n",
    "  lims = [0, 2000]\n",
    "  plt.xlim(lims)\n",
    "  plt.ylim(lims)\n",
    "  plt.plot(lims, lims, 'k', )\n",
    "  plt.xlabel('Predicted Cycle life')\n",
    "  plt.ylabel('Actual Cycle life')\n",
    "  plt.legend()\n",
    "\n",
    "normal_train_prediction = variance_model_normal_charge_tl.predict(normal_charge_train_ds['QDiffLinVar'])\n",
    "normal_test_prediction = variance_model_normal_charge_tl.predict(normal_charge_test_ds['QDiffLinVar'])\n",
    "plot_prediction(normal_train_prediction, normal_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_train_prediction2 = variance_model_normal_charge_traditional.predict(normal_charge_train_ds['QDiffLinVar'])\n",
    "normal_test_prediction2 = variance_model_normal_charge_traditional.predict(normal_charge_test_ds['QDiffLinVar'])\n",
    "plot_prediction(normal_train_prediction2, normal_test_prediction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['normal_charge_variance_model_tl'][0] = test_results['normal_charge_variance_model_tl'][0] ** 0.5\n",
    "test_results['normal_charge_variance_model_traditional'][0] = test_results['normal_charge_variance_model_traditional'][0] ** 0.5\n",
    "pd.DataFrame(test_results, index=['RMSE', 'MAE']).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
